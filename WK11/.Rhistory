}
for (k in c(3:9)){
for (j in 1:100){
bTrain <- sample(c(FALSE,TRUE),nrow(dbaDat),replace=TRUE)
tk <- tune.knn(dbaDat[bTrain,-5], dbaDat[bTrain,5], k=k )
cm <- as.matrix(table(dbaDat[-bTrain,"auth"], predict(tk$best.model,newdata=dbaDat[-bTrain,])))
ce[j,k-2] <- 1-(sum(diag(cm))/sum(cm))
}
}
tk$method
tk$best.performance
tk$best.model
tk$best.model
?tune.knn
sum(rf$confusion[,3])
rf <- randomForest(dbaDat[,-5],dbaDat$auth)
rf$confusion
sum(rf$confusion[,3])
set.seed(1234)
rf <- randomForest(dbaDat[,-5],dbaDat$auth)
rf$confusion
sum(rf$confusion[,3])
tune.knn(dbaDat[,-5],dbaDat$auth,k=1:10,tunecontrol=tune.control(sampling = "cross"), cross=10)
tk=tune.knn(dbaDat[,-5],dbaDat$auth,k=1:10,tunecontrol=tune.control(sampling = "cross"), cross=10)
tk$best.parameters
tk$best.performance
tk$method
predict(tk$best.model, dbaDat[6,])
tk$performances
plot(tk)
tk=tune.knn(dbaDat[,-5],dbaDat$auth,k=1:10,tune.control(sampling = "boot") )
tk=tune.knn(dbaDat[,-5],dbaDat$auth,k=1:10,tunecontrol=tune.control(sampling = "boot") )
plot(tk)
tk$performances
tk=tune.knn(dbaDat[,-5],dbaDat$auth,k=1:10,tunecontrol=tune.control(sampling = "boot",nboot=200) )
tk$performances
plot(tk)
plot(tk)
tk=tune.svm(auth~.,data = dbaDat[bTrain,], kernel="linear", ranges=list(cost=1:100),tunecontrol=tune.control(sampling = "boot",nboot=200) )
tk=tune.svm(auth~.,data = dbaDat[bTrain,], kernel="linear", ranges=list(cost=c(1:100)),tunecontrol=tune.control(sampling = "boot",nboot=200) )
tk=tune.svm(auth~.,data = dbaDat[bTrain,], kernel="linear", cost=c(1:100),tunecontrol=tune.control(sampling = "boot",nboot=200) )
plot(tk)
which.min(tk)
which.min(tk$best.performance)
which.min(tk$performances)
which.min(tk$performances$error)
tk=tune.svm(auth~.,data = dbaDat[bTrain,], kernel="linear", cost=c(.3:9.9),tunecontrol=tune.control(sampling = "boot",nboot=200) )
plot(tk)
3:9.9
3.1:9.9
3.1:9.9:.1
seq(1,2,.1)
ts <- tune.svm(auth~.,data = dbaDat[bTrain,], kernel="linear", cost=seq(3,9,.1),tunecontrol=tune.control(sampling = "boot",nboot=200) )
ts <- tune.svm(auth~.,data = dbaDat, kernel="linear", cost=seq(3,9,.1),tunecontrol=tune.control(sampling = "boot",nboot=100) )
ts <- tune.svm(auth~.,data = dbaDat, kernel="linear", cost=seq(4,6,.1),tunecontrol=tune.control(sampling = "boot",nboot=200) )
plot(ts)
which.min(ts$performances$error)
set.seed(1234)
tk<- tune.knn(dbaDat[,-5],dbaDat$auth,k=1:10,tunecontrol=tune.control(sampling = "boot",nboot=100) )
plot(tk)
set.seed(1234)
tk<- tune.knn(dbaDat[,-5],dbaDat$auth,k=1:10,tunecontrol=tune.control(sampling = "boot",nboot=200) )
plot(tk)
plot(tk$performances)
plot(tk$performances$error)
plot(tk$performances$error,ylab="Error %", xlab = "K")
sum(rf$confusion[,3])
?knn
tk1 <- knn(dbaDat[bTrain,-5],dbaDat[-bTrain,],k=2,cl=dbaDat$auth)
tk1 <- knn(dbaDat[bTrain,-5],dbaDat[-bTrain,],k=2,cl=dbaDat[bTrain,5])
tk1 <- knn(dbaDat[bTrain,],dbaDat[-bTrain,],k=2,cl=dbaDat[bTrain,5])
tk1
summary(tk1
)
attributes(.Last.value)
table(dbaDat[-bTrain,],tk1)
table(dbaDat[!bTrain,5],tk1)
dbaDat[!bTrain,5]
tk1
bTrain <- sample(c(FALSE,TRUE),nrow(dbaDat),replace=TRUE)
cls <- as.factor(dbaDat$auth)
tk1 <- knn(dbaDat[bTrain,],dbaDat[!bTrain,],k=2,cl=cls[bTrain])
table(dbaDat[!bTrain,],tk1)
tk1
table(dbaDat[!bTrain,5],tk1)
set.seed(1234)
ce <- matrix(nrow=100,ncol=2)
for (k in seq(1,10)){
for (j in 1:100){
bTrain <- sample(c(FALSE,TRUE),nrow(dbaDat),replace=TRUE)
cls <- as.factor(dbaDat$auth)
tk1 <- knn(dbaDat[bTrain,],dbaDat[!bTrain,],k=k,cl=cls[bTrain])
cm <- as.matrix(table(dbaDat[!bTrain,"auth"], predict(to$best.model,newdata=dbaDat[!bTrain,])))
ce[j,k] <- 1-(sum(diag(cm))/sum(cm))
}
}
boxplot(ce, xlab="Cost", ylab="Test error %")
set.seed(1234)
ce <- matrix(nrow=100,ncol=2)
for (k in seq(1,10)){
for (j in 1:100){
bTrain <- sample(c(FALSE,TRUE),nrow(dbaDat),replace=TRUE)
cls <- as.factor(dbaDat$auth)
tk1 <- knn(dbaDat[bTrain,],dbaDat[!bTrain,],k=k,cl=cls[bTrain])
cm <- as.matrix(table(dbaDat[!bTrain,5],tk1))
ce[j,k] <- 1-(sum(diag(cm))/sum(cm))
}
}
boxplot(ce, xlab="Cost", ylab="Test error %")
set.seed(1234)
ce <- matrix(nrow=100,ncol=10)
for (k in seq(1,10)){
for (j in 1:100){
bTrain <- sample(c(FALSE,TRUE),nrow(dbaDat),replace=TRUE)
cls <- as.factor(dbaDat$auth)
tk1 <- knn(dbaDat[bTrain,],dbaDat[!bTrain,],k=k,cl=cls[bTrain])
cm <- as.matrix(table(dbaDat[!bTrain,5],tk1))
ce[j,k] <- 1-(sum(diag(cm))/sum(cm))
}
}
boxplot(ce, xlab="Cost", ylab="Test error %")
points(mean(ce))
points(mean(ce),pch=2)
points(mean(ce),pch=7)
boxplot(ce, xlab="K", ylab="Test error %")
points(mean(ce),pch=7)
points(mean(ce),pch=7, col="red")
ce
tapply(ce,mean)
vapply(ce,mean)
vapply(ce,2,mean)
colMeans(ce)
points(colMeans(ce),pch=7, col="red")
points(colMeans(ce),pch=8, col="red")
points(colMeans(ce),pch=9, col="red")
boxplot(ce, xlab="K", ylab="Test error %")
points(colMeans(ce),pch=9, col="red")
boxplot(ce, xlab="K", ylab="Test error %")
points(colMeans(ce),pch=3, col="red")
set.seed(1234)
ce <- matrix(nrow=100,ncol=7)
for (k in seq(3,9)){
for (j in 1:100){
bTrain <- sample(c(FALSE,TRUE),nrow(dbaDat),replace=TRUE)
to <- tune(svm, auth~.,data = dbaDat[bTrain,], kernel="linear", ranges=list(cost=k))
cm <- as.matrix(table(dbaDat[-bTrain,"auth"], predict(to$best.model,newdata=dbaDat[-bTrain,])))
ce[j,k-2] <- 1-(sum(diag(cm))/sum(cm))
}
}
boxplot(ce, xlab="Cost", ylab="Test error %")
points(colMeans(ce),pch=3, col="red")
tune
plot(ts)
points(colMeans(ce),pch=3, col="red")
boxplot(ce, xlab="K", ylab="Test error %")
points(colMeans(ce),pch=3, col="red")
#Resampling to get error distributions
set.seed(1234)
ce <- matrix(nrow=100,ncol=10)
for (k in seq(1,10)){
for (j in 1:100){
bTrain <- sample(c(FALSE,TRUE),nrow(dbaDat),replace=TRUE)
cls <- as.factor(dbaDat$auth)
tk1 <- knn(dbaDat[bTrain,],dbaDat[!bTrain,],k=k,cl=cls[bTrain])
cm <- as.matrix(table(dbaDat[!bTrain,5],tk1))
ce[j,k] <- 1-(sum(diag(cm))/sum(cm))
}
}
boxplot(ce, xlab="K", ylab="Test error %")
points(colMeans(ce),pch=3, col="red")
svmfit=svm(auth~var+skew, data=dbaDat[bTrain,], kernel="radial", gamma=1,
cost =1)
plot(svmfit,dbaDat[bTrain])
plot(svmfit,dbaDat[bTrain,])
plot(svmfit)
d <- dbaDat[-c("var","skew"),]
head(dbaDat)
d <- dbaDat[1:2,]
d <- dbaDat[c(1,2,5),]
head(d)
d <- dbaDat[,c(1,2,5)]
svmfit=svm(auth~var+skew, data=d, kernel="radial", gamma=1,
cost =1)
plot(svmfit,d)
svm1 <-  svm(auth~var+skew, data=d, kernel="radial", gamma=.01,
cost =1)
plot(svm1, d)
svm2 <-  svm(auth~var+skew, data=d, kernel="radial", gamma=100,
cost =1)
plot(svm2, d)
plot(svm1, d, main="Gamma=.01")
title("ff")
plot(svm1, d, cex=.5)
plot(svm1, d)
plot(svm2, d)
plot(svmfit,d)
rbf.gauss <- function(gamma=1.0) {
function(x) {
exp(-gamma * norm(as.matrix(x),"F")^2 )
}
}
D <- matrix(c(-3,1,4), ncol=1) # 3 datapoints
N <- length(D[,1])
xlim  <- c(-5,7)
plot(NULL,xlim=xlim,ylim=c(0,1.25),type="n")
points(D,rep(0,length(D)),col=1:N,pch=19)
x.coord = seq(-7,7,length=250)
gamma <- 1.5
for (i in 1:N) {
points(x.coord, lapply(x.coord - D[i,], rbf.gauss(gamma)), type="l", col=i)
}
rbf(.1)
rbf.gauss(.1)
rbf.gauss(.1)(1)
rbf.gauss(10)(1)
set.seed(1234)
tune.out=tune(svm, auth~., data=dbaDat, kernel="radial",
ranges=list(cost=c(1,2,5,10,20),
gamma=c(.01,.02,.05,.1,.2) ))
plot(tune.out)
summary(tune.out)
plot(tune.out$performances)
plot(tune.out$performances$error)
plot(tune.out$performances$gamma,tune.out$performances$error)
plot(tune.out$performances$error)
plot(tune.out$performances$gamma,tune.out$performances$error)
library(lattice)
pr <- prcomp(tune.out$performances,scale=TRUE)
pr$x
scatter(pr$x$PC1,pr$x$PC2)
scatterplot(pr$x$PC1,pr$x$PC2)
plot(pr$x$PC1,pr$x$PC2)
plot(pr$x[,1],pr$x[,2])
library(scatterplot3d)
install.packages("scatterplot3d")
library(scatterplot3d)
attach(tune.out$performances)
scatterplot3d(gamma,cost,error)
tune.out$performances
scatterplot3d(x=gamma,y=cost,z=error)
scatterplot3d(x=tune.out$performances$gamma,y=tune.out$performances$cost,z=tune.out$performances$error)
plot(tune.out$performances$error)
summary(tune.out)
plot(tk$performances$error,ylab="Error %", xlab = "K")
sum(rf$confusion[,3])
plot(ts)
set.seed(1234)
ce <- matrix(nrow=100,ncol=7)
for (k in c(1,2,5,10,20)){
for (g in c(.01,.02,.05,.1,.2) ){
for (j in 1:100){
bTrain <- sample(c(FALSE,TRUE),nrow(dbaDat),replace=TRUE)
to <- tune(svm, auth~.,data = dbaDat[bTrain,], kernel="radial", cost=k, gamma=g)
cm <- as.matrix(table(dbaDat[-bTrain,"auth"], predict(to$best.model,newdata=dbaDat[-bTrain,])))
ce[j,k-2] <- 1-(sum(diag(cm))/sum(cm))
}
}
}
ce <- matrix(100,5,5)
ce
ce <- rep(NaN, 100*5*5)
ce[1,2,1]
set.seed(1234)
ce <- matrix(nrow=100,ncol=7)
for (k in seq(3,9)){
for (j in 1:100){
bTrain <- sample(c(FALSE,TRUE),nrow(dbaDat),replace=TRUE)
to <- tune(svm, auth~.,data = dbaDat[bTrain,], kernel="linear", ranges=list(cost=k))
cm <- as.matrix(table(dbaDat[!bTrain,"auth"], predict(to$best.model,newdata=dbaDat[!bTrain,])))
ce[j,k-2] <- 1-(sum(diag(cm))/sum(cm))
}
}
boxplot(ce, xlab="Cost", ylab="Test error %")
points(colMeans(ce),pch=3, col="red")
rf$confusion
1-(sum(diag(rf$confusion))/sum(rf$confusion))
set.seed(1234)
rf <- randomForest(dbaDat[,-5],dbaDat$auth)
rf$confusion
1-(sum(diag(rf$confusion))/sum(rf$confusion))
set.seed(1234)
dfTmp <- NULL
for (mtry in 1:4){
for (ntree in c(100,1000)){
for (j in 1:100){
bTrain <- sample(c(FALSE,TRUE),nrow(dbaDat),replace=TRUE)
cls <- as.factor(dbaDat$auth)
rf <- randomForest(dbaDat[bTrain,-5],cls[bTrain], mtry = mtry, ntree = ntree)
dfTmp <- rbind(dfTmp, data.frame(error=1-(sum(diag(rf$confusion))/sum(rf$confusion)),mtry=mtry,ntree=ntree))
}
}
}
genData <- function (nObs, nClassVars, nNoiseVars, deltaClass, ktries, mtries){
dfTmp <- NULL
# Simulate dataset with interaction between attribute levels associated with the outcome:
for ( iSim in 1:30 ) {
xyzTmp <- matrix(rnorm(nObs*(nClassVars+nNoiseVars)),nrow=nObs,ncol=nClassVars+nNoiseVars)
classTmp <- 1
for ( iTmp in 1:nClassVars ) {
deltaTmp <- sample(deltaClass*c(-1,1),nObs,replace=TRUE)
xyzTmp[,iTmp] <- xyzTmp[,iTmp] + deltaTmp
classTmp <- classTmp * deltaTmp
}
classTmp <- factor(classTmp > 0)
bTrain <- sample(c(FALSE,TRUE),nrow(xyzTmp),replace=TRUE)
#Random forest
if (missing(mtries)) {
rfRes <- randomForest(xyzTmp[bTrain,],classTmp[bTrain])
rfTmpTbl <- table(classTmp[!bTrain],predict(rfRes,newdata=xyzTmp[!bTrain,]))
dfTmp <- rbind(dfTmp,data.frame(type="RF",
nobs=nObs, ncvars= nClassVars, noisevars= nNoiseVars, dc=deltaClass,
err= 1-sum(diag(rfTmpTbl))/sum(rfTmpTbl)))
}
else {
for (mt in mtries){
rfRes <- randomForest(xyzTmp[bTrain,],classTmp[bTrain],mtry = mt)
rfTmpTbl <- table(classTmp[!bTrain],predict(rfRes,newdata=xyzTmp[!bTrain,]))
dfTmp <- rbind(dfTmp,data.frame(type=paste0("RF", mt),
nobs=nObs, ncvars= nClassVars, noisevars= nNoiseVars, dc=deltaClass,
err= 1-sum(diag(rfTmpTbl))/sum(rfTmpTbl)))
}
}
#LDA
ldaRes <- lda(xyzTmp[bTrain,],classTmp[bTrain])
ldaTmpTbl <- table(classTmp[!bTrain],predict(ldaRes,newdata=xyzTmp[!bTrain,])$class)
dfTmp <- rbind(dfTmp,data.frame(type="LDA",
nobs=nObs, ncvars= nClassVars, noisevars= nNoiseVars, dc=deltaClass,
err=1-sum(diag(ldaTmpTbl))/sum(ldaTmpTbl)))
#KNN
for ( kTmp in ktries ) {
knnRes <- knn(xyzTmp[bTrain,],xyzTmp[!bTrain,],classTmp[bTrain],k=kTmp)
tmpTbl <- table(classTmp[!bTrain],knnRes)
dfTmp <- rbind(dfTmp,data.frame(type=paste0("K",kTmp),
nobs=nObs, ncvars= nClassVars, noisevars= nNoiseVars, dc= deltaClass,
err=1-sum(diag(tmpTbl))/sum(tmpTbl)))
}
}
dfTmp
}
#Fixed value of KNN not to exceed 10 to prevent warnings.
dat50 <- genData(50,2,3,1,c(2,5,10))
dat200 <- genData(200,2,3,1,c(2,5,10))
dat1000 <- genData(1000,2,3,1,c(2,5,10))
q1.comb <- rbind(dat50,dat200,dat1000)
library(reshape2)
kable(q1.comb %>% dcast(type ~ nobs, mean, value.var="err"))
ggplot(q1.comb,aes(x=type,y=err,colour=type)) + geom_boxplot() + facet_wrap(~nobs)
# Fit KNN model at several levels of k:
dfTmp <- NULL
for ( kTmp in floor(1.2^(1:33)) ) {
knnRes <- knn(xyzTmp[bTrain,],xyzTmp[!bTrain,],classTmp[bTrain],k=kTmp)
tmpTbl <- table(classTmp[!bTrain],knnRes)
dfTmp <- rbind(dfTmp,data.frame(err=1-sum(diag(tmpTbl))/sum(tmpTbl),k=kTmp))
}
ggplot(dfTmp,aes(x=k,y=err))+geom_point()+scale_x_log10()+geom_hline(aes(yintercept = err,colour=type),data=data.frame(type=c("LDA","RF"),err=c(1-sum(diag(ldaTmpTbl))/sum(ldaTmpTbl),1-sum(diag(rfTmpTbl))/sum(rfTmpTbl))))+ggtitle("KNN error rate")
# How many observations:
nObs <- 1000
# How many predictors are associated with outcome:
nClassVars <- 2
# How many predictors are not:
nNoiseVars <- 1
# To modulate average difference between two classes' predictor values:
deltaClass <- 1
# Simulate dataset with interaction between attribute levels associated with the outcome:
xyzTmp <- matrix(rnorm(nObs*(nClassVars+nNoiseVars)),nrow=nObs,ncol=nClassVars+nNoiseVars)
classTmp <- 1
for ( iTmp in 1:nClassVars ) {
deltaTmp <- sample(deltaClass*c(-1,1),nObs,replace=TRUE)
xyzTmp[,iTmp] <- xyzTmp[,iTmp] + deltaTmp
classTmp <- classTmp * deltaTmp
}
classTmp <- factor(classTmp > 0)
table(classTmp)
# plot resulting attribute levels colored by outcome:
pairs(xyzTmp,col=as.numeric(classTmp))
pairs(dfTmp)
dfTmp
set.seed(1234)
dfTmp <- NULL
for (mtry in 1:4){
for (ntree in c(100,1000)){
for (j in 1:100){
bTrain <- sample(c(FALSE,TRUE),nrow(dbaDat),replace=TRUE)
cls <- as.factor(dbaDat$auth)
rf <- randomForest(dbaDat[bTrain,-5],cls[bTrain], mtry = mtry, ntree = ntree)
dfTmp <- rbind(dfTmp, data.frame(error=1-(sum(diag(rf$confusion))/sum(rf$confusion)),mtry=mtry,ntree=ntree))
}
}
}
pairs(dfTmp)
ggplot(dfTmp, aes(mtry, error))
g + geom_point() + facet_grid(. ~ ntree)
ggplot(dfTmp, aes(mtry, error)) + geom_point() + facet_grid(. ~ ntree)
ggplot(dfTmp, aes(mtry, error)) + geom_boxplot() + facet_grid(. ~ ntree)
ggplot(dfTmp, aes(mtry, error)) + geom_boxplot(group=mtry) + facet_grid(. ~ ntree)
ggplot(dfTmp, aes(mtry, error, fill=ntree)) + geom_boxplot()
ggplot(dfTmp, aes(mtry, error)) + geom_boxplot()
ggplot(dfTmp, aes(mtry, error, group=ntree)) + geom_boxplot()
ggplot(dfTmp, aes(mtry, error, group=ntree)) + geom_boxplot()  + facet_grid(~ntree)
ggplot(dfTmp, aes(mtry, error, group=mtry)) + geom_boxplot()  + facet_grid(~ntree)
randomForest(dbaDat[bTrain,-5],cls[bTrain], mtry = 5)
randomForest(dbaDat[bTrain,-5],cls[bTrain], mtry = 4)
sqrt(4)
ggplot(tune.out$performances, aes(gamma, error)) + geom_point()  + facet_grid(~cost)
summary(tune.out)
ggplot(dfTmp, aes(mtry, error, group=mtry)) + geom_boxplot()  + facet_grid(~ntree)
gTrain <- sample(c(FALSE,TRUE),nrow(dbaDat),replace=TRUE)
gLbl <- dbaDat$auth
svm.lin.model <- svm(auth~., data=dbaDat[gTrain,], kernel="linear", cost=4.3)
svm.lin.tab <- table(dbaDat[!gTrain,"auth"], predict(svm.lin.tab,newdata=dbaDat[!bTrain,]))
svm.lin.err <-  1-(sum(diag(svm.lin.tab))/sum(svm.lin.tab))
svm.lin.tab <- table(dbaDat[!gTrain,"auth"], predict(svm.lin.model,newdata=dbaDat[!bTrain,]))
svm.lin.tab <- table(dbaDat[!gTrain,"auth"], predict(svm.lin.model,newdata=dbaDat[!gTrain,]))
svm.lin.err <-  1-(sum(diag(svm.lin.tab))/sum(svm.lin.tab))
svm.lin.err
summary(ts)
set.seed(1234)
ts <- tune.svm(auth~.,data = dbaDat, kernel="linear", cost=seq(4,6,.1),tunecontrol=tune.control(sampling = "boot",nboot=100) )
summary(ts)
plot(ts)
rf
set.seed(1234)
rf <- randomForest(dbaDat[gTrain,-5],dbaDat$auth[gTrain])
rf$confusion
1-(sum(diag(rf$confusion))/sum(rf$confusion))
predict(rf,dbaDat)
rf.model <-randomForest(dbaDat[gTrain,-5],gLbl)
rf.tab <- table(dbaDat[!gTrain,"auth"], predict(rf.model,newdata=dbaDat[!gTrain,]))
rf.model <-randomForest(dbaDat[gTrain,-5],gLbl[gTrain])
set.seed(1)
svm.lin.model <- svm(auth~., data=dbaDat[gTrain,], kernel="linear", cost=4.3)
svm.lin.tab <- table(dbaDat[!gTrain,"auth"], predict(svm.lin.model,newdata=dbaDat[!gTrain,]))
svm.lin.err <-  1-(sum(diag(svm.lin.tab))/sum(svm.lin.tab))
svm.lin.err
set.seed(1)
rf.model <-randomForest(dbaDat[gTrain,-5],gLbl[gTrain])
rf.tab <- table(dbaDat[!gTrain,"auth"], predict(rf.model,newdata=dbaDat[!gTrain,]))
rf.err <-  1-(sum(diag(rf.tab))/sum(rf.tab))
rf.err
set.seed(1)
knn.model <-knn(dbaDat[gTrain,],dbaDat[!gTrain,],k=2,cl=gLbl[bTrain])
knn.tab <- table(dbaDat[!gTrain,"auth"], predict(knn.model,newdata=dbaDat[!gTrain,]))
knn.err <-  1-(sum(diag(knn.tab))/sum(knn.tab))
knn.err
knn.model <-knn(dbaDat[gTrain,],dbaDat[!gTrain,],k=2,cl=gLbl[gTrain])
set.seed(1)
knn.model <-knn(dbaDat[gTrain,],dbaDat[!gTrain,],k=2,cl=gLbl[gTrain])
knn.tab <- table(dbaDat[!gTrain,"auth"], predict(knn.model,newdata=dbaDat[!gTrain,]))
knn.err <-  1-(sum(diag(knn.tab))/sum(knn.tab))
knn.tab <- table(dbaDat[!gTrain,"auth"], predict(knn.model,newdata=dbaDat[!gTrain,-5]))
knn.model <-knn(dbaDat[gTrain,],dbaDat[!gTrain,],k=2,cl=as.factor(gLbl[gTrain]))
knn.tab <- table(dbaDat[!gTrain,"auth"], predict(knn.model,newdata=dbaDat[!gTrain,-5]))
knn.tab <- table(dbaDat[!gTrain,"auth"], predict(knn.model,newdata=dbaDat[!gTrain,]))
knn.tab <- table(dbaDat[!gTrain,"auth"], knn.model))
knn.tab <- table(dbaDat[!gTrain,"auth"], knn.model)
knn.err <-  1-(sum(diag(knn.tab))/sum(knn.tab))
knn.err
set.seed(1)
svm.radial.model <- svm(auth~., data=dbaDat[gTrain,], kernel="radial", cost=5, gamma=.05)
svm.radial.tab <- table(dbaDat[!gTrain,"auth"], predict(svm.radial.model,newdata=dbaDat[!gTrain,]))
svm.radial.err <-  1-(sum(diag(svm.radial.tab))/sum(svm.radial.tab))
svm.radial.err
kable(svm.lin.err,svm.radial.err,knn.err,rf.err)
library(knitr)
kable(svm.lin.err,svm.radial.err,knn.err,rf.err)
kable(data.frame(svm.lin.err,svm.radial.err,knn.err,rf.err))
set.seed(1234)
svm.radial.model <- svm(auth~., data=dbaDat[gTrain,], kernel="radial", cost=5, gamma=.05)
svm.radial.tab <- table(dbaDat[!gTrain,"auth"], predict(svm.radial.model,newdata=dbaDat[!gTrain,]))
svm.radial.err <-  1-(sum(diag(svm.radial.tab))/sum(svm.radial.tab))
svm.radial.err
library(knitr)
kable(data.frame(svm.lin.err,svm.radial.err,knn.err,rf.err))
summary(tune.out)
1-(sum(diag(rf$confusion))/sum(rf$confusion))
set.seed(1234)
ts.poly <- tune(svm, auth~., data=dbaDat, kernel="polynomial",
ranges=list(cost=c(1,2,5,10,20),
gamma=c(.01,.02,.05,.1,.2) ))
summary(ts.poly)
set.seed(1234)
ts.poly <- tune(svm, auth~., data=dbaDat, kernel="polynomial",tunecontrol=tune.control(sampling = "boot",nboot=100) ,
ranges=list(cost=c(1,2,5,10,20),
gamma=c(.01,.02,.05,.1,.2) ))
summary(ts.poly)
set.seed(1)
svm.poly.model <- svm(auth~., data=dbaDat[gTrain,], kernel="polynomial", cost=20, gamma=.2)
svm.poly.tab <- table(dbaDat[!gTrain,"auth"], predict(svm.poly.model,newdata=dbaDat[!gTrain,]))
svm.poly.err <-  1-(sum(diag(svm.poly.tab))/sum(svm.poly.tab))
svm.poly.err
kable(data.frame(svm.lin.err,svm.radial.err,svm.poly.err,knn.err,rf.err))
svm5 <-  svm(auth~var+skew, data=d, kernel="polynomial", gamma=.2,
cost =20)
plot(svm5, d)
tt <-tune(svm, auth~., data=d, kernel="polynomial")
tt <-tune(svm, auth~., data=d, kernel="polynomial",
ranges=list(cost=c(1,2,5,10,20),
gamma=c(.01,.02,.05,.1,.2) ))
summary(tt)
d
summary(d)
svm.poly.tab <- table(dbaDat[!gTrain,"auth"], predict(svm.poly.model,newdata=dbaDat[!gTrain,-5]))
svm.poly.err <-  1-(sum(diag(svm.poly.tab))/sum(svm.poly.tab))
svm.poly.err
svm5 <-  svm(auth~var+skew, data=d, kernel="polynomial", gamma=.2,
cost =4)
plot(svm5, d)
kable(data.frame(svm.lin.err,svm.radial.err,svm.poly.err,knn.err,rf.err))
library(neuralnet)
install.packages("neuralnet")
library(neuralnet)
library(ggplot2)
