dfTmp <- NULL
whichSum <- array(0,dim=c(7,8,4),
dimnames=list(NULL,colnames(model.matrix(PRP~.,machine.log)),
c("exhaustive", "backward", "forward", "seqrep")))
# Split data into training and test 30 tismes:
nTries <- 30
for ( iTry in 1:nTries ) {
bTrain <- sample(rep(c(TRUE,FALSE),length.out=nrow(machine.log)))
# Try each method available in regsubsets
# to select best model of each size:
for ( jSelect in c("exhaustive", "backward", "forward", "seqrep") ) {
rsTrain <- regsubsets(PRP~.,machine.log[bTrain,],method=jSelect)
# Add up variable selections:
whichSum[,,jSelect] <- whichSum[,,jSelect] + summary(rsTrain)$which
# Calculate test error for each set of variables
# using predict.regsubsets implemented above:
for ( kVarSet in 1:dim(machine.log)[2]) {
# make predictions:
testPred <- predict(rsTrain,machine.log[!bTrain,],id=kVarSet)
# calculate MSE:
mseTest <- mean((testPred-machine.log[!bTrain,"PRP"])^2)
# add to data.frame for future plotting:
dfTmp <- rbind(dfTmp,data.frame(sim=iTry,sel=jSelect,vars=kVarSet,
mse=c(mseTest,summary(rsTrain)$rss[kVarSet]/sum(bTrain)),trainTest=c("test","train")))
}
}
}
dfTmp <- NULL
whichSum <- array(0,dim=c(7,8,4),
dimnames=list(NULL,colnames(model.matrix(PRP~.,machine.log)),
c("exhaustive", "backward", "forward", "seqrep")))
# Split data into training and test 30 tismes:
nTries <- 30
for ( iTry in 1:nTries ) {
bTrain <- sample(rep(c(TRUE,FALSE),length.out=nrow(machine.log)))
# Try each method available in regsubsets
# to select best model of each size:
for ( jSelect in c("exhaustive", "backward", "forward", "seqrep") ) {
rsTrain <- regsubsets(PRP~.,machine.log[bTrain,],method=jSelect)
# Add up variable selections:
whichSum[,,jSelect] <- whichSum[,,jSelect] + summary(rsTrain)$which
# Calculate test error for each set of variables
# using predict.regsubsets implemented above:
}
}
dfTmp <- NULL
whichSum <- array(0,dim=c(7,8,4),
dimnames=list(NULL,colnames(model.matrix(PRP~.,machine.log)),
c("exhaustive", "backward", "forward", "seqrep")))
# Split data into training and test 30 tismes:
nTries <- 30
for ( iTry in 1:nTries ) {
bTrain <- sample(rep(c(TRUE,FALSE),length.out=nrow(machine.log)))
# Try each method available in regsubsets
# to select best model of each size:
for ( jSelect in c("exhaustive", "backward", "forward", "seqrep") ) {
rsTrain <- regsubsets(PRP~.,machine.log[bTrain,],method=jSelect)
# Add up variable selections:
whichSum[,,jSelect] <- whichSum[,,jSelect] + summary(rsTrain)$which
# Calculate test error for each set of variables
# using predict.regsubsets implemented above:
for ( kVarSet in 1:dim(machine.log)[2]) {
# make predictions:
testPred <- predict(rsTrain,machine.log[!bTrain,],id=kVarSet)
}
}
}
rsTrain
names(rsTrain)
testPred <- predict(rsTrain,machine.log[!bTrain,],id=1)
testPred <- predict(rsTrain,machine.log[!bTrain,],id=2)
testPred <- predict(rsTrain,machine.log[!bTrain,],id=9)
testPred <- predict(rsTrain,machine.log[!bTrain,],id=6)
testPred <- predict(rsTrain,machine.log[!bTrain,],id=7)
dfTmp <- NULL
whichSum <- array(0,dim=c(7,8,4),
dimnames=list(NULL,colnames(model.matrix(PRP~.,machine.log)),
c("exhaustive", "backward", "forward", "seqrep")))
# Split data into training and test 30 tismes:
nTries <- 30
for ( iTry in 1:nTries ) {
bTrain <- sample(rep(c(TRUE,FALSE),length.out=nrow(machine.log)))
# Try each method available in regsubsets
# to select best model of each size:
for ( jSelect in c("exhaustive", "backward", "forward", "seqrep") ) {
rsTrain <- regsubsets(PRP~.,machine.log[bTrain,],method=jSelect)
# Add up variable selections:
whichSum[,,jSelect] <- whichSum[,,jSelect] + summary(rsTrain)$which
# Calculate test error for each set of variables
# using predict.regsubsets implemented above:
for ( kVarSet in 1:dim(machine.log)[2]-1) {
# make predictions:
testPred <- predict(rsTrain,machine.log[!bTrain,],id=kVarSet)
# calculate MSE:
mseTest <- mean((testPred-machine.log[!bTrain,"PRP"])^2)
# add to data.frame for future plotting:
dfTmp <- rbind(dfTmp,data.frame(sim=iTry,sel=jSelect,vars=kVarSet,
mse=c(mseTest,summary(rsTrain)$rss[kVarSet]/sum(bTrain)),trainTest=c("test","train")))
}
}
}
dfTmp <- NULL
whichSum <- array(0,dim=c(7,8,4),
dimnames=list(NULL,colnames(model.matrix(PRP~.,machine.log)),
c("exhaustive", "backward", "forward", "seqrep")))
# Split data into training and test 30 tismes:
nTries <- 30
for ( iTry in 1:nTries ) {
bTrain <- sample(rep(c(TRUE,FALSE),length.out=nrow(machine.log)))
# Try each method available in regsubsets
# to select best model of each size:
for ( jSelect in c("exhaustive", "backward", "forward", "seqrep") ) {
rsTrain <- regsubsets(PRP~.,machine.log[bTrain,],method=jSelect)
# Add up variable selections:
whichSum[,,jSelect] <- whichSum[,,jSelect] + summary(rsTrain)$which
# Calculate test error for each set of variables
# using predict.regsubsets implemented above:
for ( kVarSet in 1:dim(machine.log)[2]-1) {
# make predictions:
testPred <- predict(rsTrain,machine.log[!bTrain,],id=kVarSet)
}
}
}
dim(rsTrain)
dfTmp <- NULL
whichSum <- array(0,dim=c(7,8,4),
dimnames=list(NULL,colnames(model.matrix(PRP~.,machine.log)),
c("exhaustive", "backward", "forward", "seqrep")))
# Split data into training and test 30 tismes:
nTries <- 30
for ( iTry in 1:nTries ) {
bTrain <- sample(rep(c(TRUE,FALSE),length.out=nrow(machine.log)))
# Try each method available in regsubsets
# to select best model of each size:
for ( jSelect in c("exhaustive", "backward", "forward", "seqrep") ) {
rsTrain <- regsubsets(PRP~.,machine.log[bTrain,],method=jSelect)
}
}
dim(rsTrain)
whichSum
dfTmp <- NULL
whichSum <- array(0,dim=c(7,8,4),
dimnames=list(NULL,colnames(model.matrix(PRP~.,machine.log)),
c("exhaustive", "backward", "forward", "seqrep")))
# Split data into training and test 30 tismes:
nTries <- 30
for ( iTry in 1:nTries ) {
bTrain <- sample(rep(c(TRUE,FALSE),length.out=nrow(machine.log)))
# Try each method available in regsubsets
# to select best model of each size:
for ( jSelect in c("exhaustive", "backward", "forward", "seqrep") ) {
rsTrain <- regsubsets(PRP~.,machine.log[bTrain,],method=jSelect)
# Add up variable selections:
whichSum[,,jSelect] <- whichSum[,,jSelect] + summary(rsTrain)$which
# Calculate test error for each set of variables
# using predict.regsubsets implemented above:
for ( kVarSet in 1:7) {
# make predictions:
testPred <- predict(rsTrain,machine.log[!bTrain,],id=kVarSet)
# calculate MSE:
mseTest <- mean((testPred-machine.log[!bTrain,"PRP"])^2)
# add to data.frame for future plotting:
dfTmp <- rbind(dfTmp,data.frame(sim=iTry,sel=jSelect,vars=kVarSet,
mse=c(mseTest,summary(rsTrain)$rss[kVarSet]/sum(bTrain)),trainTest=c("test","train")))
}
}
}
nTries <- 30
for ( iTry in 1:nTries ) {
bTrain <- sample(rep(c(TRUE,FALSE),length.out=nrow(machine.log)))
# Try each method available in regsubsets
# to select best model of each size:
for ( jSelect in c("exhaustive", "backward", "forward", "seqrep") ) {
rsTrain <- regsubsets(PRP~.,machine.log[bTrain,],method=jSelect)
# Add up variable selections:
whichSum[,,jSelect] <- whichSum[,,jSelect] + summary(rsTrain)$which
# Calculate test error for each set of variables
# using predict.regsubsets implemented above:
for ( kVarSet in 1:7) {
# make predictions:
testPred <- predict(rsTrain,machine.log[!bTrain,],id=kVarSet)
}
}
}
dfTmp <- NULL
whichSum <- array(0,dim=c(7,8,4),
dimnames=list(NULL,colnames(model.matrix(PRP~.,machine.log)),
c("exhaustive", "backward", "forward", "seqrep")))
# Split data into training and test 30 tismes:
nTries <- 30
for ( iTry in 1:nTries ) {
bTrain <- sample(rep(c(TRUE,FALSE),length.out=nrow(machine.log)))
# Try each method available in regsubsets
# to select best model of each size:
for ( jSelect in c("exhaustive", "backward", "forward", "seqrep") ) {
rsTrain <- regsubsets(PRP~.,machine.log[bTrain,],method=jSelect)
# Add up variable selections:
whichSum[,,jSelect] <- whichSum[,,jSelect] + summary(rsTrain)$which
# Calculate test error for each set of variables
# using predict.regsubsets implemented above:
for ( kVarSet in 1:6) {
# make predictions:
testPred <- predict(rsTrain,machine.log[!bTrain,],id=kVarSet)
# calculate MSE:
mseTest <- mean((testPred-machine.log[!bTrain,"PRP"])^2)
# add to data.frame for future plotting:
dfTmp <- rbind(dfTmp,data.frame(sim=iTry,sel=jSelect,vars=kVarSet,
mse=c(mseTest,summary(rsTrain)$rss[kVarSet]/sum(bTrain)),trainTest=c("test","train")))
}
}
}
dfTmp <- NULL
whichSum <- array(0,dim=c(7,8,4),
dimnames=list(NULL,colnames(model.matrix(PRP~.,machine.log)),
c("exhaustive", "backward", "forward", "seqrep")))
# Split data into training and test 30 tismes:
nTries <- 30
for ( iTry in 1:nTries ) {
bTrain <- sample(rep(c(TRUE,FALSE),length.out=nrow(machine.log)))
# Try each method available in regsubsets
# to select best model of each size:
for ( jSelect in c("exhaustive", "backward", "forward", "seqrep") ) {
rsTrain <- regsubsets(PRP~.,machine.log[bTrain,],method=jSelect)
# Add up variable selections:
whichSum[,,jSelect] <- whichSum[,,jSelect] + summary(rsTrain)$which
# Calculate test error for each set of variables
# using predict.regsubsets implemented above:
for ( kVarSet in 2:7) {
# make predictions:
testPred <- predict(rsTrain,machine.log[!bTrain,],id=kVarSet)
# calculate MSE:
mseTest <- mean((testPred-machine.log[!bTrain,"PRP"])^2)
# add to data.frame for future plotting:
dfTmp <- rbind(dfTmp,data.frame(sim=iTry,sel=jSelect,vars=kVarSet,
mse=c(mseTest,summary(rsTrain)$rss[kVarSet]/sum(bTrain)),trainTest=c("test","train")))
}
}
}
dfTmp <- NULL
whichSum <- array(0,dim=c(7,8,4),
dimnames=list(NULL,colnames(model.matrix(PRP~.,machine.log)),
c("exhaustive", "backward", "forward", "seqrep")))
# Split data into training and test 30 tismes:
nTries <- 30
for ( iTry in 1:nTries ) {
bTrain <- sample(rep(c(TRUE,FALSE),length.out=nrow(machine.log)))
# Try each method available in regsubsets
# to select best model of each size:
for ( jSelect in c("exhaustive", "backward", "forward", "seqrep") ) {
rsTrain <- regsubsets(PRP~.,machine.log[bTrain,],method=jSelect)
# Add up variable selections:
whichSum[,,jSelect] <- whichSum[,,jSelect] + summary(rsTrain)$which
# Calculate test error for each set of variables
# using predict.regsubsets implemented above:
for ( kVarSet in 1:6) {
# make predictions:
testPred <- predict(rsTrain,machine.log[!bTrain,],id=kVarSet)
# calculate MSE:
mseTest <- mean((testPred-machine.log[!bTrain,"PRP"])^2)
# add to data.frame for future plotting:
dfTmp <- rbind(dfTmp,data.frame(sim=iTry,sel=jSelect,vars=kVarSet,
mse=c(mseTest,summary(rsTrain)$rss[kVarSet]/sum(bTrain)),trainTest=c("test","train")))
}
}
}
# plot MSEs by training/test, number of
# variables and selection method:
ggplot(dfTmp,aes(x=factor(vars),y=mse,colour=sel)) + geom_boxplot()+facet_wrap(~trainTest)
mse
mseTest
dfTmp
which(dfTmp)
dfTmp[dfTmp$trainTest=="test",]
dfTmp <- NULL
whichSum <- array(0,dim=c(6,7,4),
dimnames=list(NULL,colnames(model.matrix(PRP~.,machine.log)),
c("exhaustive", "backward", "forward", "seqrep")))
# Split data into training and test 30 tismes:
nTries <- 30
for ( iTry in 1:nTries ) {
bTrain <- sample(rep(c(TRUE,FALSE),length.out=nrow(machine.log)))
# Try each method available in regsubsets
# to select best model of each size:
for ( jSelect in c("exhaustive", "backward", "forward", "seqrep") ) {
rsTrain <- regsubsets(PRP~.,machine.log[bTrain,],method=jSelect)
# Add up variable selections:
whichSum[,,jSelect] <- whichSum[,,jSelect] + summary(rsTrain)$which
# Calculate test error for each set of variables
# using predict.regsubsets implemented above:
for ( kVarSet in 1:6) {
# make predictions:
testPred <- predict(rsTrain,machine.log[!bTrain,],id=kVarSet)
# calculate MSE:
mseTest <- mean((testPred-machine.log[!bTrain,"PRP"])^2)
# add to data.frame for future plotting:
dfTmp <- rbind(dfTmp,data.frame(sim=iTry,sel=jSelect,vars=kVarSet,
mse=c(mseTest,summary(rsTrain)$rss[kVarSet]/sum(bTrain)),trainTest=c("test","train")))
}
}
}
library(ISLR)
set.seed(1)
train = sample(392, 196)
train
Auto
nrow(Auto)
lm.fit = lm(mpg~horsepower, data=Auto, subset=train)
attach(Auto)
mean((mpg - predict(lm.fit,Auto))[-train]^2)
plot(mpg~horsepower)
f = predict(lm.fit, Auto)
abline(f)
f
abline(lm.fit)
lm.fit2 = lm(mpg~poly(horsepower,2),subset=train)
abline(lm.fit2)
lm.fit2 = lm(mpg~poly(horsepower,2)
)
abline(lm.fit2)
lm.fit2
lm.fit
lines(Auto, predict(lm.fit2),col="blue") 
lm.fit2 = lm(mpg~poly(horsepower,2))
plot(Auto,mpg~horsepower)
plot(mpg~horsepower)
lines(Auto, predict(lm.fit2),col="blue") 
lines(horsepower, predict(lm.fit2),col="blue") 
order(horsepower)
sort(horsepower)
plot(mpg~horsepower)
lines(sort(horsepower), predict(lm.fit2),col="blue") 
plot(mpg~horsepower)
lines((horsepower), predict(lm.fit2),col="blue") 
plot(mpg~horsepower)
lines((horsepower), predict(lm.fit2)[order(horsepower)],col="blue") 
lines((horsepower), fitted(lm.fit2)[order(horsepower)],col="blue") 
lines((horsepower), fitted(lm.fit2)[order(horsepower)],col="blue",type="b") 
lines(sort(horsepower), fitted(lm.fit2)[order(horsepower)],col="blue") 
plot(mpg~horsepower)
lines(sort(horsepower), fitted(lm.fit2)[order(horsepower)],col="blue") 
glm.fit=glm(mpg~horsepower, data=Auto)
coef(glm.fit)
lm.fit=lm(mpg~horsepower, data=Auto)
coef(lm.fit)
library(boot)
cv.err=cv.glm(Auto, glm.fit)
cv.err$delta
cv.error = rep(0,5)
for (i in 1:5){
glm.fit = glm(mpg~poly(horsepower, i), data=Auto)
cv.error[i] = cv.glm(Auto,glm.fit)$delta[1]
}
cv.error
x = seq(1:5)
x
plot(x,cv.error)
plot(x,cv.error,type="b")
set.seed(17)
cv.error.10 = rep(0,10)
for (i in 1:10){
glm.fit = glm(mpg~poly(horsepower,i),data=Auto)
cv.error.10[i] = cv.glm(Auto, glm.fit,K=10)$delta[1]
}
x=seq(1:10=
x=seq(1:10)
plot(x, cv.error.10)
plot(x, cv.error.10,type="b")
alpha.fn=function(data,index){
X=data$X[index]
Y=data$Y[index]
return((var(Y)-cov(X,Y))/(var(X)+var(Y)-2*cov(X,Y)))
}
summary(Portfolio)
nrow(Portfolio=
)
nrow(Portfolio)
alpha.fn(Portfolio,1:100=
alpha.fn(Portfolio,1:100)
set.seed(1)
alpha.fn(Portfolio, sample(100,100, replace=T))
boot(Portfolio, alpha.fn, R=1000)
boot.fn=function(data, index)
return(coef(lm(mpg~horsepower,data=data,subset=index)))
boot.fn(Auto,1:392)
set.seed(1)
boot.fn(Auto, sample(392,392,replace=T))
boot.fn(Auto, sample(392,392,replace=T))
boot.fn(Auto, sample(392,392,replace=T))
boot(Auto, boot.fn,1000)
boot.fn = function(data, index)
coefficients(lm(mpg~horsepower + I(horsepower^2),data=data,subset=index))
set.seed(1)
boot(Auto, boot.fn,1000)
set.seed(1)
y=rnorm(100)
x=rnorm(100)
y=x-2*x^2+rnorm(100)
plot(x,y)
cv.glm(mpg~power(horsepower,5),K=10)
cv.glm(Auto,mpg~power(horsepower,5),K=10)
cv.glm(cv.glm(mpg~power(horsepower,5),data=Auto),K=10)
cv.glm(Auto,glm(mpg~power(horsepower,5),data=Auto),K=10)
cv.glm(Auto,glm(mpg~poly(horsepower,5),data=Auto),K=10)
mrge =glm(mpg~poly(horsepower,5),data=Auto)
cv.glm(Auto, mrge, K=10)
cv.glm(Auto, mrge, K=10)$delta
cv.glm(Auto, mrge, K=10)[1]
cv.glm(Auto, mrge, K=10)$delta[1]
m1 = glm(mpg~horsepower,data=Auto)
m2 = glm(mpg~poly(horsepower,2),data=Auto)
cv.glm(Auto, m1,K=10)$delta[1]
cv.glm(Auto, m2,K=10)$delta[1]
m0 = glm(mpg~0)
cv.glm(Auto, m0,K=10)$delta[1]
fix(Hitters)
names(Hitters)
Hitters = na.omit(Hitters)
dim(Hitters)
sum(is.na(Hitters))
library(leaps)
regfit.full = regsubsets(Salary~., Hitters)
summary(regfit.full)
regfit.full = regsubsets(Salary~., Hitters,nvmax=19)
summary(regfit.full)
reg.summary = summary(regfit.full)
names(reg.summary)
reg.summary$rsq
reg.summary$adjr2
x = seq(1:15)
plot(x, reg.summary$adjr2)
x
dim(reg.summary$adjr2)
len(reg.summary$adjr2)
length(reg.summary$adjr2)
x = seq(1:19)
plot(x, reg.summary$adjr2)
which.max(reg.summary$adjr2)
p=which.max(reg.summary$adjr2)
points(p, reg.summary$adjr2[p], col="red")
plot(regfit.full, scale="r2")
set.seed(1)
train = sample(c(TRUE, FALSE), nrow(Hitters), rep=TRUE)
test =(!train)
regfit.best=regsubsets(Salary~. data=Hitters[train,], nvmax=19)
regfit.best=regsubsets(Salary ~ . data=Hitters[train,], nvmax=19)
regfit.best=regsubsets(Salary ~ ., data=Hitters[train,], nvmax=19)
test.mat=model.matrix(Salary ~., data=Hitters[test,])
test.mat
val.errors=rep(NA,19)
for (i in 1:19){
coefi =coef(regfit.best, id=i)
pred=test.mat[,names(coefi)]%*%coefi
val.errors[i]=mean((Hitters$Salary[test]-pred)'2)
}
val.errors
'
for (i in 1:19){
coefi =coef(regfit.best, id=i)
pred=test.mat[,names(coefi)]%*%coefi
val.errors[i]=mean((Hitters$Salary[test]-pred)^2)
}
val.errors
which.min(val.errors)
coef(regfit.best,10)
predict.regsubsets = function(object, newdata, id ,...){
form=as.formula(object$call[[2]])
mat=model.matrix(form, newdata)
coefi=coef(object, id=id)
xvars=names(coefi)
mat[,xvars]%*%coefi
)
predict.regsubsets = function(object, newdata, id ,...){
form=as.formula(object$call[[2]])
mat=model.matrix(form, newdata)
coefi=coef(object, id=id)
xvars=names(coefi)
mat[,xvars]%*%coefi
}
regfit.best=regsubsets(Salary~.,data=Hitters,nvmax=19)
coef(regfit.best,10)
k=10
set.seed(1)
folds=sample(1:k, now(Hitters), replace=TRUE)
folds=sample(1:k, nrow(Hitters), replace=TRUE)
cv.errors=matrix(NA,k,19,dimnames=list(NULL,paste(1:19)))
cv.errors
for (j in 1:k){
best.fit =regsubsets(Salary ~., data=Hitters[folds!=j,],nvmax=19)
for (i in 1:19){
pred=predict(best.fit, Hitters[folds==j,], id=i)
cv.errors[j, i]=mean((Hitters$Salary[folds==j]-pred)^2)}}
mean.cv.errors=apply(cv.errors, 2,mean)
mean.cv.errors
plot(mean.cv.errors, type="b")
reg.best=regsubsets(Salary~., data=Hitters, nvmax=19)
coef(reg.best, 11)
which.min(mean.cv.errors)
install.packages("glmnet")
x=model.matrix(Salary~., Hitters)[,-1]
x
dim(x)
clear
x=model.matrix(Salary~., Hitters)
dim(x)
names(x)
x[20]
x[,20]
x=model.matrix(Salary~., Hitters)[,-1]
y=Hitters$Salary
library(glmnet)
grid = 10^seq(10,-2,length=100)
grid
